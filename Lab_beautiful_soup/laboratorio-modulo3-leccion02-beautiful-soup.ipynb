{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"https://github.com/Hack-io-Data/Imagenes/blob/main/01-LogosHackio/logo_naranja@4x.png?raw=true\" alt=\"esquema\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexto\n",
    "\n",
    "**Descripción:**\n",
    "\n",
    "SetMagic Productions es una empresa especializada en la provisión de servicios integrales para la realización de rodajes cinematográficos y audiovisuales. Nos dedicamos a facilitar tanto el atrezzo necesario para las producciones como los lugares idóneos para llevar a cabo los rodajes, ya sea en entornos al aire libre o en interiores.\n",
    "\n",
    "**Servicios Ofrecidos:**\n",
    "\n",
    "- **Atrezzo Creativo:** Contamos con un extenso catálogo de atrezzo que abarca desde accesorios hasta muebles y objetos temáticos para ambientar cualquier tipo de  escena.\n",
    "\n",
    "- **Locaciones Únicas:** Nuestra empresa ofrece una amplia selección de locaciones, que incluyen desde escenarios naturales como playas, bosques y montañas, hasta espacios interiores como estudios, casas históricas y edificios emblemáticos.\n",
    "- **Servicios de Producción:** Además de proporcionar atrezzo y locaciones, también ofrecemos servicios de producción audiovisual, incluyendo equipos de filmación, personal técnico y servicios de postproducción.\n",
    "\n",
    "**Herramientas y Tecnologías:**\n",
    "\n",
    "Para recopilar información sobre nuevas locaciones y tendencias en atrezzo, utilizamos herramientas de web scraping como Beautiful Soup y Selenium para extraer datos de sitios web relevantes y redes sociales especializadas en cine y producción audiovisual. También integramos APIs de plataformas de alquiler de locaciones y bases de datos de atrezzo para acceder a información actualizada y detallada.\n",
    "\n",
    "**Almacenamiento de Datos:** (A trabajar la próxima semana)\n",
    "\n",
    "La información recopilada mediante web scraping y APIs se almacenará tanto en una base de datos relacional SQL como en una base de datos no relacional MongoDB . Estas base de datos nos permite organizar eficientemente la información sobre locaciones, atrezzo, clientes y proyectos en curso, facilitando su acceso y gestión.\n",
    "\n",
    "**Objetivo:**\n",
    "\n",
    "Nuestro objetivo principal es proporcionar a nuestros clientes una experiencia fluida y personalizada en la búsqueda y selección de locaciones y atrezzo para sus proyectos audiovisuales. Utilizando tecnologías avanzadas y una amplia red de contactos en la industria, nos esforzamos por ofrecer soluciones creativas y de alta calidad que satisfagan las necesidades específicas de cada producción.\n",
    "\n",
    "\n",
    "## Lab: Extracción de Información con Beautiful Soup\n",
    "\n",
    "En este laboratorio seguirás enriqueciendo la base de datos para ofrecer a tus clientes un servicio más completo y personalizado. Para lograr esto, extraerás información valiosa sobre objetos de atrezzo de una web especializada. Utilizarás técnicas de web scraping con la biblioteca **Beautiful Soup** para obtener y organizar los datos de manera eficiente.\n",
    "\n",
    "Trabajarás con la siguiente URL: [Atrezzo Vázquez](https://atrezzovazquez.es/shop.php?search_type=-1&search_terms=&limit=48&page=1). Esta página contiene una gran cantidad de objetos de atrezzo que pueden ser de interés para un proyecto de rodaje. Tu tarea será extraer información relevante de los productos listados en las primeras 100 páginas.\n",
    "\n",
    "1. **Navegación y Extracción de Múltiples Páginas**:\n",
    "\n",
    "   - La página web contiene varios elementos distribuidos en distintas páginas. Tu objetivo será iterar a través de las 100 primeras páginas y extraer la información deseada.\n",
    "\n",
    "   - Debes asegurarte de que tu código sea capaz de navegar automáticamente por estas páginas y extraer datos de manera continua.\n",
    "\n",
    "2. **Verificación del Código de Estado de la Respuesta**:\n",
    "\n",
    "   - Antes de extraer cualquier información, es fundamental verificar que la solicitud a la página web ha sido exitosa. Un código de estado 200 indica que la página se ha cargado correctamente.\n",
    "\n",
    "   - Si el código no es 200, debes imprimir un mensaje de error y detener la ejecución de la extracción para evitar problemas posteriores.\n",
    "\n",
    "3. **Extracción de Información Específica**:\n",
    "\n",
    "   De cada página, deberás extraer los siguientes detalles de los objetos de atrezzo:\n",
    "\n",
    "   - **Nombre del Objeto**: El nombre o identificador del objeto.\n",
    "\n",
    "   - **Categoría**: La categoría en la que se clasifica el objeto (ej.: mobiliario, decorado, utilería, etc.).\n",
    "\n",
    "   - **Sección**: La sección específica dentro de la categoría.\n",
    "\n",
    "   - **Descripción**: Una breve descripción del objeto que puede incluir detalles sobre su estilo, material o uso.\n",
    "\n",
    "   - **Dimensiones**: El tamaño del objeto en formato (largo x ancho x alto).\n",
    "\n",
    "   - **Enlace a la Imagen**: El link a la imagen del objeto, útil para tener una vista previa visual.\n",
    "\n",
    "4. **Organización de los Datos en un Diccionario**:\n",
    "\n",
    "   Una vez extraída la información, deberás organizarla en un diccionario con las siguientes claves:\n",
    "\n",
    "   - `\"nombre\"`: Nombres del objeto.\n",
    "\n",
    "   - `\"categoria\"`: Categoría a la que pertenece el objeto.\n",
    "\n",
    "   - `\"seccion\"`: Sección específica dentro de la categoría.\n",
    "\n",
    "   - `\"descripcion\"`: Breve descripción del objeto.\n",
    "\n",
    "   - `\"dimensiones\"`: Dimensiones del objeto en el formato adecuado.\n",
    "\n",
    "   - `\"imagen\"`: URL de la imagen del objeto.\n",
    "\n",
    "5. **Almacenamiento de la Información en un DataFrame**:\n",
    "\n",
    "   Una vez que tengas toda la información organizada en diccionarios, el siguiente paso es convertirla en un DataFrame de Pandas. Este DataFrame te permitirá manipular y analizar los datos con facilidad. Tu DataFrame debería verse similar al ejemplo proporcionado, donde cada fila representa un objeto diferente y cada columna contiene la información extraída:\n",
    "\n",
    "![Dataframe](https://github.com/Hack-io-Data/Imagenes/blob/main/02-Imagenes/BS/df_atrezzo.png?raw=true)\n",
    "\n",
    "\n",
    "6.  Consideraciones Adicionales:\n",
    "\n",
    "- Asegúrate de manejar posibles errores o excepciones durante el scraping, como tiempos de espera agotados, páginas inaccesibles o datos faltantes.\n",
    "\n",
    "- Recuerda que el scraping debe hacerse de manera respetuosa, evitando sobrecargar el servidor de la página web (puedes usar pausas entre solicitudes).\n",
    "\n",
    "- Finalmente, asegúrate de almacenar el DataFrame en un archivo CSV para que puedas reutilizar esta información en análisis futuros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías que necesitamos\n",
    "import numpy as np\n",
    "# Librerías de extracción de datos\n",
    "# -----------------------------------------------------------------------\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "# Tratamiento de datos\n",
    "# -----------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import time\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion buena\n",
    "def web(sopa,df):\n",
    "\n",
    "    lista_info = sopa.findAll('div', {'class': \"col-md-3 col-sm-4 shop-grid-item\"})\n",
    "\n",
    "    descripciones= [element.find('p').getText() for element in lista_info]\n",
    "\n",
    "    # Sacar nombres\n",
    "    lista_nombres = sopa.findAll('a', {'class': 'title'})\n",
    "    nombres_objetos = [nombre.getText() for nombre in lista_nombres]\n",
    "    # Sacar categorías\n",
    "    lista_categorias = sopa.findAll('div', {'class': 'cat-sec-box'})\n",
    "    nombre_categorias = [ncat.getText().replace('\\xa0\\xa0','') for ncat in lista_categorias]\n",
    "    # Sección\n",
    "    lista_secciones_if = []\n",
    "    for elemento in lista_info:\n",
    "        try:\n",
    "            lista_secciones_if.append(elemento.find('a', {'class':'tag'}).text)\n",
    "        except:\n",
    "            lista_secciones_if.append(np.nan)\n",
    "\n",
    "    # print(len(lista_secciones_if))\n",
    "    # lista_secciones = sopa_atrezzo.findAll('a', {'class': 'tag'})\n",
    "    # nombre_secciones = [nsec.getText() for nsec in lista_secciones]\n",
    "\n",
    "    # Descripción\n",
    "\n",
    "    lista_img = []\n",
    "    for elemento in lista_info:\n",
    "        try:\n",
    "            lista_img.append(elemento.find('img')['src'])\n",
    "        except:\n",
    "            lista_img.append(np.nan)\n",
    "    # print(len(lista_img))\n",
    "    # Enlace a imagen\n",
    "    # lista_imagen = sopa_atrezzo.findAll('img')\n",
    "    # lista_imagen = [link.get('src') for link in lista_imagen]\n",
    "\n",
    "    lista_dimensiones= sopa.findAll('div', {'class': 'price'})\n",
    "    nombre_dimensiones = [dimensiones.getText().strip() for dimensiones in lista_dimensiones]\n",
    "    # for i in nombre_dimensiones:\n",
    "    #     i.getText().strip()\n",
    "    diccionario = {'nombre': nombres_objetos, 'categoria': nombre_categorias, 'seccion': lista_secciones_if, 'descripcion': descripciones, 'dimensiones': nombre_dimensiones, 'imagen': lista_img}\n",
    "    df_articulos = pd.DataFrame(diccionario)\n",
    "    df = pd.concat([df, df_articulos])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "#funcion final prueba\n",
    "df_lleno = pd.DataFrame()\n",
    "df_final = pd.DataFrame()\n",
    "for i in range(1,101):\n",
    "    url_atrezzo = f'https://atrezzovazquez.es/shop.php?search_type=-1&search_terms=&limit=48&page={i}'\n",
    "    # Paso 2\n",
    "    response = requests.get(url_atrezzo)\n",
    "    # Paso 3\n",
    "    if str(response) == '<Response [200]>':\n",
    "        print(response.status_code)\n",
    "        # Paso 4\n",
    "        sopa_atrezzo = (BeautifulSoup(response.content, 'html.parser'))\n",
    "        df_final = web(sopa_atrezzo, df_final)\n",
    "        df_lleno = pd.concat([df_lleno, df_final])\n",
    "        time.sleep(random.uniform(1,3))\n",
    "    else: \n",
    "        print('Hay un error')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre</th>\n",
       "      <th>categoria</th>\n",
       "      <th>seccion</th>\n",
       "      <th>descripcion</th>\n",
       "      <th>dimensiones</th>\n",
       "      <th>imagen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALF1</td>\n",
       "      <td>Arabe</td>\n",
       "      <td>Alfombra</td>\n",
       "      <td>Alfombra persa marrón (tiene unas manchas que ...</td>\n",
       "      <td>460x340x1 (cm)</td>\n",
       "      <td>admin/img_prod/ALF1/ALF1-720x540.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADO1</td>\n",
       "      <td></td>\n",
       "      <td>Adornos</td>\n",
       "      <td>Vitrina con abanico</td>\n",
       "      <td>100x10x60 (cm)</td>\n",
       "      <td>admin/img_prod/ADO1/ADO1-720x540.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFC1</td>\n",
       "      <td>Dormitorio</td>\n",
       "      <td>Alfombra de cama</td>\n",
       "      <td>Alfombrín de cama círculos azules</td>\n",
       "      <td>150x72x1 (cm)</td>\n",
       "      <td>admin/img_prod/AFC1/AFC1-720x540.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP1</td>\n",
       "      <td>AlemánComedor</td>\n",
       "      <td>Aparador</td>\n",
       "      <td>Aparador alemán 2 cuerpos</td>\n",
       "      <td>207x64x300 (cm)</td>\n",
       "      <td>admin/img_prod/AP1/AP1-720x540.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AST1</td>\n",
       "      <td>Astronomía</td>\n",
       "      <td>Atrezzo astronomia</td>\n",
       "      <td>Pie de madera para astrolabio</td>\n",
       "      <td>78x78x130 (cm)</td>\n",
       "      <td>admin/img_prod/AST1/AST1-pie-720x540.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nombre      categoria             seccion  \\\n",
       "0   ALF1          Arabe            Alfombra   \n",
       "1   ADO1                            Adornos   \n",
       "2   AFC1     Dormitorio    Alfombra de cama   \n",
       "3    AP1  AlemánComedor            Aparador   \n",
       "4   AST1     Astronomía  Atrezzo astronomia   \n",
       "\n",
       "                                         descripcion      dimensiones  \\\n",
       "0  Alfombra persa marrón (tiene unas manchas que ...   460x340x1 (cm)   \n",
       "1                                Vitrina con abanico   100x10x60 (cm)   \n",
       "2                  Alfombrín de cama círculos azules    150x72x1 (cm)   \n",
       "3                          Aparador alemán 2 cuerpos  207x64x300 (cm)   \n",
       "4                      Pie de madera para astrolabio   78x78x130 (cm)   \n",
       "\n",
       "                                     imagen  \n",
       "0      admin/img_prod/ALF1/ALF1-720x540.png  \n",
       "1      admin/img_prod/ADO1/ADO1-720x540.png  \n",
       "2      admin/img_prod/AFC1/AFC1-720x540.png  \n",
       "3        admin/img_prod/AP1/AP1-720x540.png  \n",
       "4  admin/img_prod/AST1/AST1-pie-720x540.png  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de este, saqué la funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# prueba para uno\n",
    "url_atrezzo = f'https://atrezzovazquez.es/shop.php?search_type=-1&search_terms=&limit=48&page=1'\n",
    "# Paso 2\n",
    "response = requests.get(url_atrezzo)\n",
    "# Paso 3\n",
    "if str(response) == '<Response [200]>':\n",
    "    print(response.status_code)\n",
    "    # Paso 4\n",
    "    sopa_atrezzo = (BeautifulSoup(response.content, 'html.parser'))\n",
    "    time.sleep(random.uniform(1,3))\n",
    "else: \n",
    "    print('Hay un error')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 16017.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 23998.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lista_info = sopa_atrezzo.findAll('div', {'class': \"col-md-3 col-sm-4 shop-grid-item\"})\n",
    "\n",
    "descripciones= [element.find('p').getText() for element in lista_info]\n",
    "\n",
    "# Sacar nombres\n",
    "lista_nombres = sopa_atrezzo.findAll('a', {'class': 'title'})\n",
    "nombres_objetos = [nombre.getText() for nombre in lista_nombres]\n",
    "# Sacar categorías\n",
    "lista_categorias = sopa_atrezzo.findAll('div', {'class': 'cat-sec-box'})\n",
    "nombre_categorias = [ncat.getText().replace('\\xa0\\xa0','') for ncat in lista_categorias]\n",
    "# Sección\n",
    "lista_secciones_if = []\n",
    "for elemento in tqdm(lista_info):\n",
    "    try:\n",
    "        lista_secciones_if.append(elemento.find('a', {'class':'tag'}).text)\n",
    "    except:\n",
    "        lista_secciones_if.append(np.nan)\n",
    "\n",
    "print(len(lista_secciones_if))\n",
    "# lista_secciones = sopa_atrezzo.findAll('a', {'class': 'tag'})\n",
    "# nombre_secciones = [nsec.getText() for nsec in lista_secciones]\n",
    "\n",
    "# Descripción\n",
    "\n",
    "lista_img = []\n",
    "for elemento in tqdm(lista_info):\n",
    "    lista_img.append(elemento.find('img')['src'])\n",
    "print(len(lista_img))\n",
    "# Enlace a imagen\n",
    "# lista_imagen = sopa_atrezzo.findAll('img')\n",
    "# lista_imagen = [link.get('src') for link in lista_imagen]\n",
    "\n",
    "lista_dimensiones= sopa_atrezzo.findAll('div', {'class': 'price'})\n",
    "nombre_dimensiones = [dimensiones.getText().strip() for dimensiones in lista_dimensiones]\n",
    "\n",
    "diccionario = {'nombre': nombres_objetos, 'categoria': nombre_categorias, 'seccion': lista_secciones_if, 'descripcion': descripciones, 'dimensiones': nombre_dimensiones, 'imagen': lista_img}\n",
    "df_articulos = pd.DataFrame(diccionario)\n",
    "df = pd.DataFrame()\n",
    "df = pd.concat([df, df_articulos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 6)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "48\n",
      "48\n",
      "48\n",
      "48\n",
      "48\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "print(len(nombre_dimensiones))\n",
    "print(len(lista_img))\n",
    "print(len(nombre_dimensiones))\n",
    "print(len(lista_secciones_if))\n",
    "print(len(nombre_categorias))\n",
    "print(len(nombres_objetos))\n",
    "print(len(descripciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
